{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I have no idea what I\\'m doing, but for the record that\\'s something I really feel good about,\" Cascia told ESPNU at the time. \"I just feel like I\\'m going for a little bit of peace and not be concerned'},\n",
       " {'generated_text': 'I have no idea what I\\'m doing, but you feel very happy!\" I told him. \"I am grateful, but it\\'s a little more of a mental health issue.\" He laughed. \"I am trying! I would never like that in'},\n",
       " {'generated_text': \"I have no idea what I'm doing, but I guess I must have lost my faith in God. [He is] a poor man who hates his children. And then, when he thinks he's doing something wrong, he becomes mad and runs\"},\n",
       " {'generated_text': 'I have no idea what I\\'m doing, but my wife is looking forward to the day my son turns 2!\"\\n\\nHolly has been a nurse since she was young.\\n\\nHolly and her husband had four children but her older brother'},\n",
       " {'generated_text': \"I have no idea what I'm doing, but I am going to fix it in a few weeks.\\n\\nThis story was brought to you by: Vastly popular and highly recommended site,\\n\\nhttp://vastly.com I\"}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample from the HuggingFace GPT-2 model.\n",
    "\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model=\"gpt2\")\n",
    "set_seed(42)\n",
    "generator(\"I have no idea what I'm doing, but\", max_length=50, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have no idea what I'm doing, but I'm really interested to understand if something as simple as something as this... could be the secret behind it and how the same thing can be used in so many different ways.\n",
      "In terms of being\n",
      "I have no idea what I'm doing, but thanks.\"\n",
      "\"The answer to my question, or so many questions...\"\n",
      "\"It's not clear, but I really love this question of my very own, and I have never been particularly excited\n",
      "I have no idea what I'm doing, but it's fun!\n",
      "It's been a busy week, too...\n",
      "I had to cut out the paper for my own project, too. I did not have time for this project, so that\n"
     ]
    }
   ],
   "source": [
    "# Sample from my own GPT-2 model.\n",
    "\n",
    "import torch\n",
    "from model import GPT, GPTConfig\n",
    "\n",
    "checkpoint = torch.load(\"log/model_19072.pt\", weights_only=False)\n",
    "model_state_dict = {k.replace(\"_orig_mod.\", \"\") : v for k, v in checkpoint[\"model_state_dict\"].items()}\n",
    "model = GPT(GPTConfig())\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "text = model.generate(\"I have no idea what I'm doing, but\", length=50, num_of_generated_sequences=3, device=\"cuda\")\n",
    "for t in text:\n",
    "    print(t)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
